{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Transformer CTC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SiBV44AXY1Dp",
        "9OXCnHqEY1Dp",
        "3U_g3-wrY1Dq",
        "CwSKmwgXY1Dq"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivaylojelev/fastai1/blob/master/Transformer_CTC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDSbmbNcY1DV"
      },
      "source": [
        "# Prelims"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "xuvxfPzaY1DX"
      },
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "6A129th_Y1DY"
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks.tracker import *"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "al4QPI7yY1DY"
      },
      "source": [
        "PATH = Path('drive/MyDrive/Thesis/data/iam')"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMfjZWDWY1DY",
        "outputId": "5923202e-8c00-410e-f661-d3526ab65593"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L__C1WB-Saeq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZY8PKXY1DZ"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "m-1dLA3YY1DZ"
      },
      "source": [
        "def show_img(im, figsize=None, ax=None, alpha=None, title=None):\n",
        "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
        "    ax.imshow(image2np(im.data), alpha=alpha)\n",
        "    if title: ax.set_title(title)\n",
        "    return ax"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "t8vyfuTJY1DZ"
      },
      "source": [
        "def rshift(tgt, bos_token=1):\n",
        "    \"Shift y to the right by prepending token\"\n",
        "    bos = torch.zeros((tgt.size(0),1), device=device).type_as(tgt) + bos_token\n",
        "    return torch.cat((bos, tgt[:,:-1]), dim=-1)\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    return torch.tril(torch.ones((1,size,size), device=device).byte())"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3liijsl3Y1DZ"
      },
      "source": [
        "## Loss, Metrics, Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "WhHf5VckY1Da"
      },
      "source": [
        "class LabelSmoothing(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        \n",
        "    def forward(self, pred, target):\n",
        "        pred,targ = self.loss_prep(pred, target)\n",
        "        pred = F.log_softmax(pred, dim=-1)        # necessary for KLDivLoss\n",
        "        true_dist = pred.data.clone()\n",
        "        true_dist.fill_(self.smoothing / pred.size(1)) \n",
        "        #print(true_dist)  \n",
        "        #print(targ.shape)      \n",
        "        true_dist.scatter_(1, targ.data.unsqueeze(1), self.confidence)  # [0.0012, 0.0012, 0.90, 0.0012]\n",
        "        #print(F.kl_div(pred, true_dist, reduction='sum')/bs)\n",
        "        return F.kl_div(pred, true_dist, reduction='sum')/bs\n",
        "    \n",
        "    def loss_prep(self, pred, target):\n",
        "        \"equalize input/target sl; combine bs/sl dimensions\"\n",
        "        bs,tsl = target.shape\n",
        "        _ ,sl,vocab = pred.shape\n",
        "\n",
        "        # F.pad( front,back for dimensions: 1,0,2 )\n",
        "        if sl>tsl: target = F.pad(target, (0,sl-tsl))\n",
        "        if tsl>sl: pred = F.pad(pred, (0,0,0,tsl-sl))\n",
        "\n",
        "        targ = target.contiguous().view(-1).long()\n",
        "        pred = pred.contiguous().view(-1, vocab)\n",
        "        return pred, targ"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gDGEwMkcGnb",
        "outputId": "0e97f8e7-da17-43cc-fe14-26b05fc5a1a5"
      },
      "source": [
        "!pip install Levenshtein"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.7/dist-packages (0.16.0)\n",
            "Requirement already satisfied: rapidfuzz<1.9,>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from Levenshtein) (1.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "bl6q0W62Y1Da"
      },
      "source": [
        "import Levenshtein as Lev\n",
        "\n",
        "class CER(Callback):\n",
        "    def __init__(self, fn, dump_fn=None):\n",
        "        super().__init__()\n",
        "        self.name = 'cer'\n",
        "        self.fn = fn\n",
        "        self.dump_fn = dump_fn\n",
        "        if dump_fn:\n",
        "          init_csv_dump(dump_fn)\n",
        "\n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.errors, self.total = 0, 0\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        error,size = cer(last_output.cpu(), last_target.cpu(), self.fn, self.dump_fn)\n",
        "        self.errors += error\n",
        "        self.total += size\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        return add_metrics(last_metrics, self.errors/self.total)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cs08QjYZ8qn"
      },
      "source": [
        "class TKER(Callback):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.name = 'tker'\n",
        "        self.fn = fn\n",
        "\n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.errors, self.total = 0, 0\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        error,size = tker(last_output.cpu(), last_target.cpu(), self.fn)\n",
        "        self.errors += error\n",
        "        self.total += size\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        return add_metrics(last_metrics, self.errors/self.total)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdu5jde0mscL"
      },
      "source": [
        "class WER(Callback):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.name = 'wer'\n",
        "        self.fn = fn\n",
        "\n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.errors, self.total = 0, 0\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        error,size = wer(last_output.cpu(), last_target.cpu(), self.fn)\n",
        "        self.errors += error\n",
        "        self.total += size\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        return add_metrics(last_metrics, self.errors/self.total)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "9-VXW2QmY1Da"
      },
      "source": [
        "def cer(preds, targs, fn, export_fn=None):\n",
        "    bs = targs.size(0)\n",
        "    #print(\"Target tensor: \")\n",
        "    #print(targs)\n",
        "    res = torch.argmax(preds, dim=-1)\n",
        "    error = 0\n",
        "    for i in range(bs):\n",
        "        #print(fn(targs[i]))\n",
        "        p_re = fn(res[i])\n",
        "        t_re = fn(targs[i])\n",
        "\n",
        "        p = str(p_re)\n",
        "        t = str(t_re)\n",
        "\n",
        "        #print(\"Char prediction: \", p)\n",
        "        #print(\"Char GT: \", t)\n",
        "\n",
        "        if export_fn:\n",
        "          with open(export_fn, 'a') as csvfile:\n",
        "            csv_writer = csv.writer(csvfile, delimiter=' ')\n",
        "            csv_writer.writerow([p.replace(' ', '|'), t.replace(' ', '|')])\n",
        "\n",
        "        \n",
        "        #print(\"Character Distance: \", Lev.distance(t, p))\n",
        "        error += Lev.distance(t, p)/(len(t) or 1)\n",
        "    return error, bs\n",
        "\n",
        "def init_csv_dump(filename):\n",
        "    with open(filename, 'w') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile, delimiter=' ')\n",
        "        csv_writer.writerow(['prediction', 'ground_truth'])"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8Qve2c8c76P",
        "outputId": "b0881a2b-fe72-4088-d244-3723cfa172f9"
      },
      "source": [
        "pip install editdistance"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (0.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKtbABNjagOT"
      },
      "source": [
        "import editdistance\n",
        "\n",
        "def tker(preds, targs, fn):\n",
        "    bs = targs.size(0)\n",
        "    #print(\"Target tensor: \")\n",
        "    #print(targs)\n",
        "    res = torch.argmax(preds, dim=-1)\n",
        "    error = 0\n",
        "    for i in range(bs):\n",
        "        p = fn(res[i])\n",
        "        t = fn(targs[i])\n",
        "\n",
        "        #print(\"Token Prediction: \", p)\n",
        "        #print(\"Token Ground truth: \", t)\n",
        "        \n",
        "        dist = editdistance.eval(p, t)\n",
        "        #print(\"Token Distance: \", dist)\n",
        "        error += dist / (len(t) or 1)\n",
        "\n",
        "    return error, bs"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EW7LpJGm9Qd"
      },
      "source": [
        "import string\n",
        "\n",
        "def wer(preds, targs, fn):\n",
        "    bs = targs.size(0)\n",
        "    #print(\"Target tensor: \")\n",
        "    #print(targs)\n",
        "    res = torch.argmax(preds, dim=-1)\n",
        "    error = 0\n",
        "    for i in range(bs):\n",
        "        #print(fn(targs[i]))\n",
        "        p_re = fn(res[i])\n",
        "        t_re = fn(targs[i])\n",
        "\n",
        "        p = str(p_re)\n",
        "        t = str(t_re)\n",
        "\n",
        "        p = p.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "        t = t.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "        w_p = [w for w in p.split(' ') if w != '']\n",
        "        w_t = [w for w in t.split(' ') if w != '']\n",
        "\n",
        "        #print(\"Word predictions: \", w_p)\n",
        "        #print(\"Word targets: \", w_t)\n",
        "\n",
        "        dist = editdistance.eval(w_p, w_t)\n",
        "        #print(\"Word Distance: \", dist)\n",
        "        error += dist / (len(w_t) or 1)\n",
        "\n",
        "    return error, bs"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "JWWPCsWOY1Db"
      },
      "source": [
        "class TeacherForce(LearnerCallback):\n",
        "    def __init__(self, learn:Learner):\n",
        "        super().__init__(learn)\n",
        "        \n",
        "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
        "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUTiJwC3Y1Db"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "C0cII3dHY1Dc"
      },
      "source": [
        "## handwriting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H08h-Q0BjRCQ",
        "outputId": "1f2f76b6-aba3-4c33-bb04-e27917c2337b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "H8ecR58GY1Dd"
      },
      "source": [
        "#handwriting only\n",
        "fname = 'dataset_short.csv'\n",
        "FOLDER = 'lines'"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JHgEDK3LWHS"
      },
      "source": [
        "def logits(x):\n",
        "  x[x == 0.0] += 1.0e-06\n",
        "  x[x == 1.0] -= 1.0e-06\n",
        "\n",
        "  x = x / (1.0 - x)\n",
        "  x = np.log(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "uquAAxBxY1Dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b5f900-86dd-4102-fcc8-3261e7ade2e1"
      },
      "source": [
        "CSV = PATH/fname\n",
        "df = pd.read_csv(CSV, delimiter = ' ')\n",
        "\n",
        "sz,bs = 100,15\n",
        "seq_len,word_len = 750,300\n",
        "len(df)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLiaczr9Y1Dd"
      },
      "source": [
        "# ModelData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKFbEkVVaHAL"
      },
      "source": [
        "class MatrixBase(ItemBase):\n",
        "  def __init__(self, px:Tensor):\n",
        "      self.data = px\n",
        "      self.obj = px\n",
        "      self._logit_px = None\n",
        "\n",
        "  def clone(self):\n",
        "      return self.__class__(self.data.clone())\n",
        "\n",
        "  @property\n",
        "  def logit_px(self)->LogitTensorImage:\n",
        "      \"Get logit(image.px).\"\n",
        "      if self._logit_px is None: self._logit_px = logit_(self.px)\n",
        "      return self._logit_px\n",
        "\n",
        "  def get_logits(self):\n",
        "    self.data = self.obj - self.logit_px()\n",
        "\n",
        "  def __str__(self):\n",
        "    return str(self.data)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRkSrUeHbxc-"
      },
      "source": [
        "class MatrixList(ItemList):\n",
        "  def get(self, i):\n",
        "    fn = super().get(i)\n",
        "    mat = np.genfromtxt(self.path/fn, delimiter=';', names=None)\n",
        "    res = torch.from_numpy(mat.astype(np.float32, copy=False))\n",
        "    return MatrixBase(res)\n",
        "\n",
        "  \n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQBiRjgzY1Dd"
      },
      "source": [
        "## SentencePiece"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ5hEKhfOZ0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b31f64-f527-40ce-d910-f4f2110a869e"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "9qk62ksPY1Dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbed97d-8caa-4548-8af1-117578779815"
      },
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(str(PATH/'spm_iam_corpus.model'))\n",
        "sp.SetEncodeExtraOptions(\"eos\")\n",
        "sp.SetDecodeExtraOptions(\"bos:eos\")"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "N33SAyOlY1Dd"
      },
      "source": [
        "def add_cap_tokens(text):  # before encode\n",
        "    #print(text)\n",
        "    text = text.replace('|', ' ')\n",
        "    re_caps = re.compile(r'[A-Z]+')\n",
        "    return re_caps.sub(_replace_caps, text)\n",
        "    \n",
        "def _replace_caps(m):\n",
        "    tok = '[UP]' if m.end()-m.start() > 1 else '[MAJ]'\n",
        "    return tok + m.group().lower()\n",
        "\n",
        "def remove_cap_tokens(text):  # after decode\n",
        "    text = text.replace(' \\u2047 MAJ \\u2047 ', '[MAJ]')\n",
        "    text = text.replace(' \\u2047 UP \\u2047 ', '[UP]')\n",
        "    text = text.replace(' \\u2047 ', '')\n",
        "    \n",
        "    text = re.sub(r'\\[UP\\]\\w+', lambda m: m.group()[4:].upper(), text)  #cap entire word\n",
        "    text = re.sub(r'\\[MAJ\\]\\w?', lambda m: m.group()[5:].upper(), text) #cap first letter\n",
        "    \n",
        "    return text\n",
        "\n",
        "def remove_cap_pieces(pieces):\n",
        "    #print(\"Before decap:\", pieces)\n",
        "    no_cap = []\n",
        "    #open_tag = False\n",
        "    for piece in pieces:\n",
        "      if piece != '<unk>': #and not open_tag:\n",
        "        no_cap.append(piece)\n",
        "      #if piece == '<unk>':\n",
        "      #  open_tag = not open_tag\n",
        "\n",
        "    \n",
        "    #print(\"After decap:\", no_cap)\n",
        "    return no_cap"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "q0v0Nm6_Y1De"
      },
      "source": [
        "### Word only (development)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "7W79nK1qY1De"
      },
      "source": [
        "bs=20"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "0da929MDY1De"
      },
      "source": [
        "def label_collater(samples:BatchSamples, pad_idx:int=0):\n",
        "    \"Function that collect samples and pads ends of labels.\"\n",
        "    data = to_data(samples)\n",
        "    ims, lbls = zip(*data)\n",
        "    imgs = torch.stack(list(ims))\n",
        "    if len(data) is 1 and lbls[0] is 0:   #predict\n",
        "        labels = torch.zeros(1,1).long()\n",
        "        return imgs, labels    \n",
        "    max_len = max([len(s) for s in lbls])\n",
        "    labels = torch.zeros(len(data), max_len+1).long() + pad_idx  # add 1 to max_len to account for bos token\n",
        "    for i,lbl in enumerate(lbls):\n",
        "        labels[i,:len(lbl)] = torch.from_numpy(lbl)  #padding end    \n",
        "    return imgs, labels"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "49bazH8nY1De"
      },
      "source": [
        "class SPMTokenizer(BaseTokenizer):\n",
        "    def tokenizer(self, t:str) -> List[str]: \n",
        "      #print(\"From tokenizer: \", t)\n",
        "      #print(\"Encoded: \", sp.EncodeAsIds(t))\n",
        "      return sp.EncodeAsIds(t)[1:]\n",
        "\n",
        "class SPMProcessor(PreProcessor):\n",
        "    def __init__(self, ds:ItemList=None, chunksize:int=10000):\n",
        "        self.toknizr = Tokenizer(tok_func=SPMTokenizer, pre_rules=[rm_useless_spaces, add_cap_tokens],\n",
        "                                 post_rules=[], special_cases=[])\n",
        "        self.chunksize = chunksize\n",
        "        \n",
        "    def process_one(self, item):\n",
        "        raise Exception(\"This isn't implemented!  I didn't think it was necessary...\")\n",
        "    \n",
        "    def process(self, ds):\n",
        "        tokens = []\n",
        "        for i in progress_bar(range(0,len(ds),self.chunksize), leave=False):\n",
        "            #print(tokens)\n",
        "            #ds.items = [item.replace('|', ' ') for item in ds.items]\n",
        "            #print(ds.items)\n",
        "            tokens += self.toknizr.process_all(ds.items[i:i+self.chunksize])\n",
        "        ds.items = tokens\n",
        "\n",
        "class SPMList(ItemList):\n",
        "    _processor = [SPMProcessor]\n",
        "\n",
        "    def __init__(self, items:Iterator, sp, **kwargs):\n",
        "        super().__init__(items, **kwargs)\n",
        "        self.vocab = sp\n",
        "        self.pad_idx = 0\n",
        "        self.copy_new += ['vocab']\n",
        "\n",
        "    def get(self, i):\n",
        "        o = super().get(i)\n",
        "        return Text(o, self.textify(o))\n",
        "\n",
        "    def reconstruct(self, t:Tensor):\n",
        "        return Text(t, self.textify(t))\n",
        "    \n",
        "    def textify(self, ids):\n",
        "        if isinstance(ids, torch.Tensor): ids = ids.tolist()\n",
        "        st = self.vocab.DecodeIds(ids)\n",
        "        st = remove_cap_tokens(st)\n",
        "        return st\n",
        "\n",
        "    def get_pieces(self, ids):\n",
        "        if isinstance(ids, torch.Tensor): ids = ids.tolist()\n",
        "        \n",
        "        pieces = [ self.vocab.IdToPiece(id) for id in ids ]\n",
        "        pieces = remove_cap_pieces(pieces)\n",
        "\n",
        "        return pieces"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "ozrQISmxY1De",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "055a8551-db01-4a3d-ed22-8911231c0a26"
      },
      "source": [
        "data = (MatrixList.from_df(df, path=PATH/FOLDER)\n",
        "        .split_by_rand_pct(valid_pct=0.20, seed=42)\n",
        "        .label_from_df(label_cls=SPMList, sp=sp)\n",
        "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
        "        )"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPT-cgZCpR5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7e56f3-819a-4845-c4d3-63021abab01b"
      },
      "source": [
        "data"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataBunch;\n",
              "\n",
              "Train: LabelList (420 items)\n",
              "x: MatrixList\n",
              "tensor([[0.8221, 0.9528, 0.2055,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0485, 0.9999, 0.9809,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0313, 0.9999, 0.9916,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.8296, 0.8133, 0.4072,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0025, 1.0000, 0.9963,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0018, 1.0000, 0.9960,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.9771, 0.9784, 0.2208,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.1601, 0.9999, 0.9788,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.1294, 1.0000, 0.9867,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.7774, 0.9985, 0.2486,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0586, 1.0000, 0.9966,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.1265, 1.0000, 0.9994,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.7033, 0.9954, 0.2628,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0445, 1.0000, 0.9970,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0436, 1.0000, 0.9968,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
              "y: SPMList\n",
              "to be made at a meeting of Labour,P for Manchester Exchange .,A MOVE to stop Mr. Gaitskell from nominating,more Labour life Peers is to be made at a,Foot has put down a resolution on the subject\n",
              "Path: drive/MyDrive/Thesis/data/iam/lines;\n",
              "\n",
              "Valid: LabelList (105 items)\n",
              "x: MatrixList\n",
              "tensor([[0.9819, 0.9658, 0.2310,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0163, 1.0000, 0.9977,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0157, 1.0000, 0.9939,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.5114, 0.6440, 0.0472,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0109, 0.9998, 0.9482,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0019, 1.0000, 0.9857,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.9126, 0.8048, 0.5674,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0639, 0.9999, 0.9978,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.1053, 1.0000, 0.9989,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.8172, 0.9996, 0.0510,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0304, 1.0000, 0.8449,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0619, 1.0000, 0.9785,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),tensor([[0.7306, 0.9638, 0.0751,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0192, 0.9999, 0.9803,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0322, 1.0000, 0.9870,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
              "y: SPMList\n",
              "the problem with Dr. Brentano ,,angry uproar . One dealt with the human,of Labour 0MPS tomorrow . Mr. Michael,right to delay progress in the talks by,insisting on a policy of change .\n",
              "Path: drive/MyDrive/Thesis/data/iam/lines;\n",
              "\n",
              "Test: None"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "lXum5EgdY1Dh"
      },
      "source": [
        "# Transformer Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "FlWT6biQY1Dh"
      },
      "source": [
        "# LayerNorm = nn.LayerNorm\n",
        "LayerNorm = partial(nn.LayerNorm, eps=1e-4)  # eps: 1e-4 accomodates mixed precision training"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "SM6jwBd-Y1Di"
      },
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    \"A residual connection followed by a layer norm.  Note: (for code simplicity) norm is first.\"\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "5xd8rDNUY1Di"
      },
      "source": [
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([deepcopy(module) for _ in range(N)])"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "42mUY_acY1Di"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #print(\"Shape of tensor passed to the encoding layers: \")\n",
        "        #print(x.shape)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return self.norm(x)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "QhSomLVjY1Di"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"Encoder: self-attn and feed forward\"\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "y_NaBVwjY1Di"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"Generic N layer decoder with masking.\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "        \n",
        "    def forward(self, x, src, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src, tgt_mask)\n",
        "        return self.norm(x)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "UyoLndUnY1Di"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"Decoder: self-attn, src-attn, and feed forward\"\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)  # wraps layer in residual,dropout,norm\n",
        " \n",
        "    def forward(self, x, src, tgt_mask=None):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))  # acts as a weak LM\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, src, src))\n",
        "        return self.sublayer[2](x, self.feed_forward)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "_UZpxb8rY1Di"
      },
      "source": [
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    depth = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(depth)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e4)  #changed from: -1e9 to accomodate mixed precision  \n",
        "    p_attn = F.softmax(scores, dim=-1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "nUSdBOVGY1Di"
      },
      "source": [
        "class SingleHeadedAttention(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.2):\n",
        "        super(SingleHeadedAttention, self).__init__()\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, query, key, value, mask=None):        \n",
        "        query, key, value = [l(x) for l, x in zip(self.linears, (query, key, value))]\n",
        "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
        "        return self.linears[-1](x)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "wHcwXGlUY1Dj"
      },
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, d_model, h=8, dropout=0.2):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        self.d_k = d_model // h        # assume d_v always equals d_k\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        if mask is not None: mask = mask.unsqueeze(1)\n",
        "        bs = q.size(0)\n",
        "        \n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
        "        q, k, v = [l(x).view(bs, -1, self.h, self.d_k).transpose(1,2) for l, x in zip(self.linears, (q, k, v))]\n",
        "        \n",
        "        # 2) Apply attention on all the projected vectors in batch. \n",
        "        x, self.attn = attention(q, k, v, mask=mask, dropout=self.dropout)\n",
        "        \n",
        "        # 3) \"Concat\" using a view and apply a final linear. \n",
        "        x = x.transpose(1, 2).contiguous().view(bs, -1, self.h * self.d_k)\n",
        "        return self.linears[-1](x)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "zygSpSvxY1Dj"
      },
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.2):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_model*4)\n",
        "        self.w_2 = nn.Linear(d_model*4, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.gelu(self.w_1(x))))"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "U5RIv_YGY1Dj"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=2000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0.0, max_len).unsqueeze(1)\n",
        "        log_increment = math.log(1e4) / d_model\n",
        "        div_term = torch.exp(torch.arange(0.0, d_model, 2) * -log_increment)  \n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe.unsqueeze_(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)    #(1,max_len,d_model)\n",
        "        # registered buffers are Tensors (not Variables)\n",
        "        # not a parameter but still want in the state_dict\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "2GLvmbwEY1Dj"
      },
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDu6ezmJY1Dj"
      },
      "source": [
        "# SentencePiece Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "v2Pa8bwbY1Dj"
      },
      "source": [
        "## Word Arch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "2flSQIujY1Dj"
      },
      "source": [
        "class LearnedPositionalEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab, dropout=0.1):\n",
        "        super(LearnedPositionalEmbeddings, self).__init__()\n",
        "        self.nl_tok  = 4\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.embed = nn.Embedding(vocab, d_model, 0)\n",
        "        self.rows = nn.Embedding(15, d_model//2, 0)\n",
        "        self.w_cols = nn.Embedding(60, d_model//2, 0)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rows,cols = self.encode_spatial_positions(x)\n",
        "        \n",
        "        row_t = self.rows(rows)            \n",
        "        col_t = self.w_cols(torch.clamp(cols, max=self.w_cols.num_embeddings-1))  # clamp to max column value\n",
        "        pos_enc = torch.cat((row_t, col_t), dim=-1)\n",
        "                \n",
        "        x = self.embed(x)\n",
        "        x = (x + pos_enc) * math.sqrt(self.d_model)\n",
        "        return self.dropout(x)\n",
        "    \n",
        "    def encode_spatial_positions(self, x):\n",
        "        rows,cols = torch.zeros_like(x),torch.zeros_like(x)\n",
        "        for ii,batch in enumerate(x.unbind()):\n",
        "            nls = torch.nonzero(batch==self.nl_tok).flatten()\n",
        "            last = torch.nonzero(batch).flatten()[-1][None]\n",
        "            splits = torch.cat([nls,last])\n",
        "\n",
        "            p=0\n",
        "            for i,n in enumerate(splits, start=1):\n",
        "                rows[ii,p:n+1] = i\n",
        "                cols[ii,p:n+1] = torch.arange(1,n-p+2)\n",
        "                p = n+1\n",
        "        return rows,cols"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "qw0oM0nqY1Dj"
      },
      "source": [
        "class ResnetBase(nn.Module):\n",
        "    def __init__(self, em_sz):\n",
        "        super().__init__()\n",
        "        \n",
        "        slices = {128: -4, 256: -3, 512: -2}\n",
        "        s = slices[em_sz]\n",
        "\n",
        "        net = models.resnet18(True)\n",
        "        modules = list(net.children())[:s]\n",
        "        self.base = nn.Sequential(*modules)                  #32x32 : 256\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # IVO\n",
        "        return x\n",
        "        return self.base(x)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "rK-sKzBqY1Dk"
      },
      "source": [
        "class Adaptor(nn.Module):\n",
        "    def forward(self, x):\n",
        "        # IVO check out this too\n",
        "        # NB! It might be to adapt the img data to a sequentially processed one\n",
        "        # It might help you with passing it from the matrices\n",
        "        #print(\"Before adapting\")\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "        x = x.flatten(2,3).permute(0,2,1)\n",
        "\n",
        "        #assert False\n",
        "        return x.mul(8)\n",
        "        ## IVO\n",
        "        # return x OR\n",
        "        # return logit(x)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "hLYuNyT8Y1Dk"
      },
      "source": [
        "class WordTransformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, embeddings, generator):\n",
        "        super(WordTransformer, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.w_decoder = decoder\n",
        "        self.embed = embeddings\n",
        "        self.generator = generator\n",
        "            \n",
        "    def forward(self, src, tgt):\n",
        "        #print(\"Source to the transformer\")\n",
        "        #print(src)\n",
        "        #print(src.dtype)\n",
        "        tgt = rshift(tgt, 1).long()\n",
        "        mask = subsequent_mask(tgt.size(-1))\n",
        "        return self.w_decoder(self.embed(tgt), self.encoder(src), mask)\n",
        "\n",
        "    def generate(self, outs):\n",
        "        return self.generator(outs)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "5lk--n_pY1Dk"
      },
      "source": [
        "def make_full_model(vocab, d_model, N=4, drops=0, heads=8):\n",
        "    c = deepcopy\n",
        "    attn = MultiHeadedAttention(d_model, heads)\n",
        "    ff = PositionwiseFeedForward(d_model, drops)\n",
        "    \n",
        "    model = WordTransformer(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), drops), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), drops), N),\n",
        "        LearnedPositionalEmbeddings(d_model, vocab, drops),  #word\n",
        "        nn.Linear(d_model, vocab),\n",
        "    )\n",
        "        \n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "                    \n",
        "    return model"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "mfYur2DUY1Dk"
      },
      "source": [
        "class Img2Seq(nn.Module):\n",
        "    def __init__(self, adaptor, transformer): #img_encoder, \n",
        "        super(Img2Seq, self).__init__()\n",
        "        #self.img_enc = img_encoder\n",
        "        self.adaptor = adaptor\n",
        "        self.transformer = transformer\n",
        "        \n",
        "    def forward(self, src, tgt=None, seq_len=300):\n",
        "        if tgt is not None:   #train\n",
        "            feats = self.adaptor(src)#self.img_enc(\n",
        "            #print(\"Shape of input: \")\n",
        "            #print(src)\n",
        "            #print(src.shape)\n",
        "\n",
        "            #print(\"Shape of the features after adapting: \")\n",
        "            #print(feats)\n",
        "            #print(feats.shape)\n",
        "            # IVO Here is where you trace the data\n",
        "            outs = self.transformer(feats, tgt)\n",
        "            return self.transformer.generate(outs)\n",
        "        else:                 #predict\n",
        "            self.eval()\n",
        "            with torch.no_grad():\n",
        "                feats = self.transformer.encoder(self.adaptor(src))\n",
        "                tgt = torch.ones((src.size(0),1), dtype=torch.long, device=device)\n",
        "\n",
        "                res = []\n",
        "                for i in progress_bar(range(seq_len)):\n",
        "                    emb = self.transformer.embed(tgt)\n",
        "                    #mask = subsequent_mask(tgt.size(-1))\n",
        "                    dec_outs = self.transformer.w_decoder(emb, feats)#, mask)\n",
        "                    prob = self.transformer.generate(dec_outs[:,-1])\n",
        "                    res.append(prob)\n",
        "                    pred = torch.argmax(prob, dim=-1, keepdim=True)\n",
        "                    if (pred==0).all(): break\n",
        "                    tgt = torch.cat([tgt,pred], dim=-1)\n",
        "                return torch.stack(res).transpose(1,0).contiguous()"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "cC0IYNBbY1Dk"
      },
      "source": [
        "def make_learner(data, d_model, em_sz, N=4, drops=0.1, heads=8, smoothing=0.1, dump_name=None):\n",
        "    #img_encoder = ResnetBase(em_sz)\n",
        "    ## IVO \n",
        "    ## em_sz is the output of the CNN or the dimension of the features\n",
        "    adaptor = Adaptor()\n",
        "    transformer = make_full_model(10000, d_model, N, drops, heads)\n",
        "    net = Img2Seq(adaptor, transformer)\n",
        "    dump_file = None if not dump_name else PATH/dump_name\n",
        "    learn = Learner(data, net, loss_func=LabelSmoothing(smoothing), \n",
        "                    metrics=[CER(data.y.reconstruct, dump_file),\n",
        "                             TKER(data.y.get_pieces),\n",
        "                             WER(data.y.reconstruct)], \n",
        "                    callback_fns=[TeacherForce])  #remove for export\n",
        "    return learn"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY3RmJ9AdUwk"
      },
      "source": [
        "bs = 20\n",
        "emb_size = 128\n",
        "model_size = 128"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "-cxbVhW1Y1Dk"
      },
      "source": [
        "learn = make_learner(data, model_size, emb_size, N=4, drops=0.1, heads=1, dump_name='dump/dump_1.0.csv')"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "irUxi6p0Y1Dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015fb4fc-9d26-42e2-c061-c993751beb5b"
      },
      "source": [
        "# number of trainable parameters\n",
        "sum(p.numel() for p in learn.model.parameters() if p.requires_grad)\n",
        "# 50,873,424"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4426704"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "_ZQVPAUJY1Dk"
      },
      "source": [
        "# sd = torch.load(PATH/'models/font_sp10k.pth', map_location=device)\n",
        "# learn.model.load_state_dict(sd['model'], strict=False)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "fTUO-DYbY1Dm"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "bmCfYg0FY1Dm"
      },
      "source": [
        "lrs = 1e-2"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "aJ5576eSY1Dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "c63f6dc4-e3f8-425d-b7ed-8fa304383e6b"
      },
      "source": [
        "learn.fit_one_cycle(2, max_lr=lrs, start_epoch=0, callbacks=[SaveModelCallback(learn, every='epoch', name='full_model_1.0')])\n",
        "\n",
        "# arch: (512, 512, N=4, drops=0.1, heads=8); subsequent_masks; lpe\n",
        "# sentence_piece10k\n",
        "\n",
        "# data: small dataset, sz:256, bs:50\n",
        "\n",
        "# combo, 67.7M, 5cycle(1e-3)   \n",
        "# 10.024531\t10.917119\t0.059539\t0.100420\t08:22\n",
        "# chars:    1.71376   .10433\n",
        "# words:    1.56690   .06228\n",
        "\n",
        "\n",
        "# data: font generated, sz:512, bs:15\n",
        "\n",
        "# combo, 67.7M, 3cycle(1e-3)\n",
        "# 31.972498\t28.244387\t0.017639\t0.037072\t1:45:40   'font_sp10k'\n",
        "# chars:    32.2701   .01937\n",
        "# words:    41.7109   .02917\n",
        "\n",
        "\n",
        "# data: handwriting, sz:512, bs:15\n",
        "\n",
        "# combo, 67.7M, 5cycle(1e-3)\n",
        "# 14.077939\t11.943507\t0.006205\t0.003816\t21:38   'hw_sp10k'\n",
        "# chars:    50.1363   .00435\n",
        "# words:    5.17031   .00043\n",
        "# test pg:\n",
        "# chars:    144.698   .03923\n",
        "# words:    80.1309   .04630\n",
        "# test upload:\n",
        "# chars:    129.044   .26124\n",
        "# words:    61.2923   .30572\n",
        "\n",
        "\n",
        "# combo, 2cycle(1e-4), preload hw_sp10k\n",
        "# 12.602509\t11.120279\t0.005010\t0.002936\t20:04    'hw_sp10k5'\n",
        "# test pg:\n",
        "# chars:    152.536   .03506\n",
        "# words:    86.5458   .04597\n",
        "# test upload:\n",
        "# chars:    131.504   .35796\n",
        "# words:    59.7730   .27973\n",
        "\n",
        "# word only, 3cycle(1e-4), preload hw_sp10k\n",
        "# 6.081270\t6.041916\t0.000911\t14:51    'word_hw_sp10k' ****\n",
        "#     pg:    82.7050   .04591\n",
        "#     pg:    83.1463   .04556  no mask\n",
        "# upload:    64.2214   .31966\n",
        "# upload:    61.1524   .30548  no mask"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/2 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>cer</th>\n",
              "      <th>tker</th>\n",
              "      <th>wer</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='5' class='' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      23.81% [5/21 00:12<00:41 314.1885]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-172-263ec539c4c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSaveModelCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_model1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# arch: (512, 512, N=4, drops=0.1, heads=8); subsequent_masks; lpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# sentence_piece10k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfCkjuWUkS8j"
      },
      "source": [
        "curr_version = '0.1'\n",
        "learn.save('transformer_ctc_' + curr_version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqYksqE5EDux"
      },
      "source": [
        "learn.recorder.plot_losses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "doZvRJ6cY1Dm"
      },
      "source": [
        "assert False\n",
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "bR5Q1ve2Y1Dm"
      },
      "source": [
        "learn.recorder.plot(suggestion=True)\n",
        "#learn.load('hw_sp10k'); None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azZuhAQAAs6b"
      },
      "source": [
        "# K-fold validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n_HQxtxTaLJ"
      },
      "source": [
        "num_folds = 2\n",
        "val_split = 0.2\n",
        "part_size = math.floor(len(df) * val_split)\n",
        "num_epochs = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWe835FXJ0QO"
      },
      "source": [
        "import random\n",
        "\n",
        "idxs = [*range(len(df))]\n",
        "random.shuffle(idxs)\n",
        "\n",
        "err_rates = []\n",
        "\n",
        "err_rates_log = PATH/'err_rates_1.0.csv'\n",
        "\n",
        "with open(err_rates_log, 'w') as csvfile:\n",
        "  csv_writer = csv.writer(csvfile, delimiter=',')\n",
        "  csv_writer.writerow(['fold', 'loss', 'cer', 'tkerr', 'wer'])\n",
        "\n",
        "for k in range(num_folds):\n",
        "  print(\"Fold #\", k+1)\n",
        "  \n",
        "  start_int = k * part_size\n",
        "  end_int = start_int + part_size\n",
        "\n",
        "  valid_idx = idxs[start_int:end_int]\n",
        "  train_idx = idxs[:start_int] + idxs[end_int:]\n",
        "\n",
        "  data = (MatrixList.from_df(df, path=PATH/FOLDER)\n",
        "        .split_by_idxs(train_idx=train_idx, valid_idx=valid_idx)\n",
        "        .label_from_df(label_cls=SPMList, sp=sp)\n",
        "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
        "        )\n",
        "  \n",
        "  dump_fn = 'dump/dump_k_fold_' + str(k) + '.csv'\n",
        "  model_name = 'model_k_fold_' + str(k)\n",
        "  \n",
        "  learn = make_learner(data, model_size, emb_size, \n",
        "                       N=4, \n",
        "                       drops=0.1, \n",
        "                       heads=1, \n",
        "                       dump_name=dump_fn)\n",
        "  \n",
        "  learn.fit_one_cycle(num_epochs, max_lr=lrs, start_epoch=0, \n",
        "                      callbacks=[SaveModelCallback(\n",
        "                          learn, every='epoch', name=model_name)])\n",
        "\n",
        "  acc = learn.validate(data.valid_dl)\n",
        "  print(\"Loss, CER, tkERR and WER for fold \", k, \": \", acc)\n",
        "\n",
        "  err_rates.append(acc)\n",
        "\n",
        "  with open(err_rates_log, 'a') as csvfile:\n",
        "            csv_writer = csv.writer(csvfile, delimiter=',')\n",
        "            csv_writer.writerow([k] + acc)\n",
        "\n",
        "#for train_idx, val_idx in skf.split(df['label'],df['name']):\n",
        "#  print(train_idx, val_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "mTXTWgIOY1Dm"
      },
      "source": [
        "# View Model Telemetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "WuXFMPBfY1Dn"
      },
      "source": [
        "class FullStats(HookCallback):\n",
        "    def on_train_begin(self, **kwargs):\n",
        "        self.modules = [m for m in flatten_model(self.learn.model) if hasattr(m, 'weight')]\n",
        "        self.g_hooks = Hooks(self.modules, self.g_hook, is_forward=False)\n",
        "        self.a_hooks = Hooks(self.modules, self.a_hook)\n",
        "        self.grads,self.acts = [],[]\n",
        "\n",
        "    def g_hook(self, m:nn.Module, i:Tensors, o:Tensors)->Tuple[Rank0Tensor,Rank0Tensor]:\n",
        "        oo = next(o)\n",
        "        return oo.mean().item(),oo.std().item()\n",
        "    \n",
        "    def a_hook(self, m:nn.Module, i:Tensors, o:Tensors)->Tuple[Rank0Tensor,Rank0Tensor]:\n",
        "        return o.mean().item(),o.std().item()\n",
        "\n",
        "    def on_batch_end(self, train, **kwargs):\n",
        "        if train:\n",
        "            self.acts.append(self.a_hooks.stored)\n",
        "            self.grads.append(self.g_hooks.stored)\n",
        "            \n",
        "    def on_train_end(self, **kwargs):\n",
        "        self.a_hooks.remove()\n",
        "        self.g_hooks.remove()\n",
        "        self.acts = tensor(self.acts).permute(2,1,0)\n",
        "        self.grads = tensor(self.grads).permute(2,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "tFGysCMfY1Dn"
      },
      "source": [
        "learn.fit(1, 1e-5, callbacks=[FullStats(learn)])#, StopAfterNBatches(n_batches=2)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "75dw6B4pY1Dn"
      },
      "source": [
        "acts,grads = learn.full_stats.acts, learn.full_stats.grads\n",
        "acts.shape,grads.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "26KCVKFDY1Dn"
      },
      "source": [
        "names=[]\n",
        "for name, param in learn.model.named_parameters():\n",
        "    if name.endswith('weight'):\n",
        "        names.append(name)\n",
        "\n",
        "names.insert(193, 'transformer.w_embed.embed.weight')\n",
        "names.insert(194, 'transformer.w_embed.rows.weight')\n",
        "len(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "0LQYas4XY1Dn"
      },
      "source": [
        "# :64     img_enc\n",
        "# 64:67   adaptor\n",
        "# 67:84   encoder\n",
        "# 84:137  c_decoder\n",
        "# 137:190 w_decoder\n",
        "# 190:    embeddings/generator\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "for l in acts[1,137:190]:\n",
        "    plt.plot(l)\n",
        "plt.legend(names[137:190])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "EdMXve8gY1Dn"
      },
      "source": [
        "avg_act_stds_by_layer = acts[1,:].mean(-1)\n",
        "avg_grad_stds_by_layer = grads[1,:].mean(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "1jZPeldcY1Dn"
      },
      "source": [
        "plt.plot(avg_act_stds_by_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "3bhFRcfWY1Do"
      },
      "source": [
        "plt.plot(avg_grad_stds_by_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "wnG8m8SyY1Do"
      },
      "source": [
        "for (i,mod),a,g in zip(enumerate(names), avg_act_stds_by_layer, avg_grad_stds_by_layer):\n",
        "    mod_name = str(mod).split('(')[0]\n",
        "    print(f\"{str(i).ljust(3)} {mod_name.ljust(60)} \\\n",
        "            {str(round(a.item(),5)).ljust(6)} {str(round(g.item(),5)).ljust(6)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "UGhSFbRQY1Dp"
      },
      "source": [
        "# Last batch activations by layer\n",
        "\n",
        "for (i,mod),m,s in zip(enumerate(names), acts[0,:,-1], acts[1,:,-1]):\n",
        "    mod_name = str(mod).split('(')[0]\n",
        "    print(f\"{str(i).ljust(3)} {mod_name.ljust(50)} \\\n",
        "            {str(round(m.item(),5)).ljust(6)}  {str(round(s.item(),5)).ljust(6)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qwiuKHSY1Dp"
      },
      "source": [
        "# Char/Word Greedy results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "Iw-4vgOJY1Dp"
      },
      "source": [
        "def greedy_decode(src, model, seq_len, kind='char', bos_tok=1):\n",
        "    model.eval()\n",
        "    tfmr = model.transformer\n",
        "    img_enc = model.img_enc\n",
        "    adaptor = model.adaptor\n",
        "    decoder = tfmr.c_decoder if kind=='char' else tfmr.w_decoder\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        feats = tfmr.encoder(adaptor(img_enc(src)))\n",
        "        bs = src.size(0)\n",
        "        tgt = torch.zeros((bs,1), dtype=torch.long, device=device) + bos_tok\n",
        "\n",
        "        res = []\n",
        "        for i in progress_bar(range(seq_len)):\n",
        "            mask = subsequent_mask(tgt.size(-1))\n",
        "            emb = tfmr.embed.encode_one(tgt, kind)\n",
        "#             emb = tfmr.embed(tgt)\n",
        "            \n",
        "            dec_outs = decoder(emb, feats, mask)\n",
        "            prob = tfmr.generator(dec_outs[:,-1])\n",
        "            res.append(prob)\n",
        "            pred = torch.argmax(prob, dim=-1, keepdim=True)\n",
        "            if (pred==0).all(): break\n",
        "            tgt = torch.cat([tgt,pred], dim=-1)\n",
        "        out = torch.stack(res).transpose(1,0).contiguous()\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "C6BUuXCjY1Dp"
      },
      "source": [
        "vdl = iter(learn.data.valid_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "hT0sHLt1Y1Dp"
      },
      "source": [
        "x,y = next(vdl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "SiBV44AXY1Dp"
      },
      "source": [
        "### Single Word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "dSoNNaHYY1Dp"
      },
      "source": [
        "# g_preds = greedy_decode(x, learn.model, word_len, 'word', 1)\n",
        "g_preds = learn.model(x)\n",
        "g_res = torch.argmax(g_preds, dim=-1)\n",
        "g = [learn.loss_func(g_preds, y).item()/bs, cer(g_preds, y, data.y.reconstruct)[0]/bs]\n",
        "print(f'greedy:    {str(g[0])[:7]}   {str(g[1])[1:7]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "ragXd-6RY1Dp"
      },
      "source": [
        "#greedy\n",
        "fig, axes = plt.subplots(2,2, gridspec_kw={'hspace': 0.4}, figsize=(18, 20))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    #i += 8\n",
        "    p = data.y.reconstruct(g_res[i])\n",
        "    ax=show_img(x[i], ax=ax, title=p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "9OXCnHqEY1Dp"
      },
      "source": [
        "### Single Char"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "Cm80IhT9Y1Dp"
      },
      "source": [
        "g_preds = greedy_decode(x, learn.model, seq_len, 'char')\n",
        "g_res = torch.argmax(g_preds, dim=-1)\n",
        "g = [learn.loss_func(g_preds, y).item()/bs, cer(g_preds, y, data.y.reconstruct)[0]/bs]\n",
        "print(f'greedy:    {str(g[0])[:7]}   {str(g[1])[1:7]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "4qjiKdH-Y1Dq"
      },
      "source": [
        "#greedy\n",
        "fig, axes = plt.subplots(2,2, gridspec_kw={'hspace': 0.4}, figsize=(18, 20))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    p = data.y.reconstruct(g_res[i])\n",
        "    ax=show_img(x[i], ax=ax, title=p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-01T17:02:56.281776Z",
          "start_time": "2019-11-01T17:02:53.656973Z"
        },
        "heading_collapsed": true,
        "id": "3U_g3-wrY1Dq"
      },
      "source": [
        "### Combo Chars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "uDVBAqMtY1Dq"
      },
      "source": [
        "g_preds = greedy_decode(x, learn.model, seq_len, 'char', 1)\n",
        "g_res = torch.argmax(g_preds, dim=-1)\n",
        "loss_func = LabelSmoothing()\n",
        "g = [loss_func(g_preds, y[0]).item()/bs, cer(g_preds, y[0], data.y.reconstruct_one)[0]/bs]\n",
        "print(f'greedy:    {str(g[0])[:7]}   {str(g[1])[1:7]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "D_zPbqpmY1Dq"
      },
      "source": [
        "#greedy\n",
        "fig, axes = plt.subplots(3,2, gridspec_kw={'hspace': 0.4}, figsize=(18, 20))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    p = data.y.reconstruct_one(g_res[i])\n",
        "    ax=show_img(x[i], ax=ax, title=p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-01T17:02:56.281776Z",
          "start_time": "2019-11-01T17:02:53.656973Z"
        },
        "heading_collapsed": true,
        "id": "CwSKmwgXY1Dq"
      },
      "source": [
        "### Combo Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "sge-45WkY1Dq"
      },
      "source": [
        "g_preds = greedy_decode(x, learn.model, word_len, 'word', 1, lm=False)\n",
        "g_res = torch.argmax(g_preds, dim=-1)\n",
        "loss_func = LabelSmoothing()\n",
        "g = [loss_func(g_preds, y[1]).item()/bs, cer(g_preds, y[1], data.y.reconstruct_one)[0]/bs]\n",
        "print(f'greedy:    {str(g[0])[:7]}   {str(g[1])[1:7]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "scrolled": true,
        "id": "cbniKs5eY1Dq"
      },
      "source": [
        "#greedy\n",
        "fig, axes = plt.subplots(3,2, gridspec_kw={'hspace': 0.4}, figsize=(18, 20))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    p = data.y.reconstruct_one(g_res[i])\n",
        "    ax=show_img(x[i], ax=ax, title=p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yli2i_QY1Dq"
      },
      "source": [
        "# Test Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "cI4do9JyY1Dr"
      },
      "source": [
        "FOLDER = 'uploads'\n",
        "df = pd.read_csv(PATH/'uploads.csv')\n",
        "len(df)\n",
        "\n",
        "sz,bs = 512,14\n",
        "seq_len = 700"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "BICcLG3zY1Dr"
      },
      "source": [
        "FOLDER = 'paragraphs'\n",
        "df = pd.read_csv(PATH/'test_pg.csv')\n",
        "len(df)\n",
        "\n",
        "sz,bs = 512,15\n",
        "seq_len = 700"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "8Fac9J0OY1Dr"
      },
      "source": [
        "# sentencepiece combo\n",
        "test_data = (ImageMultiList.from_df(df, path=PATH, folder=FOLDER, after_open=force_gray)\n",
        "        .split_none()\n",
        "        .label_from_df(label_cls=SPMMultiList, sp=sp)\n",
        "        .transform([], size=sz, resize_method=ResizeMethod.SQUISH)\n",
        "        .databunch(bs=bs, device=device, collate_fn=multi_label_collater)\n",
        "       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "L5KBKiPRY1Dr"
      },
      "source": [
        "# sentencepiece word\n",
        "test_data = (ImageList.from_df(df, path=PATH, folder=FOLDER, after_open=force_gray)\n",
        "        .split_none()\n",
        "        .label_from_df(label_cls=SPList)\n",
        "        .transform([], size=sz, resize_method=ResizeMethod.SQUISH)\n",
        "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
        "       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "L1gk39haY1Dr"
      },
      "source": [
        "x,y = next(iter(test_data.train_dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {},
        "id": "swNWmpr6Y1Dr"
      },
      "source": [
        "# Export Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "n9gAuXuBY1Dr"
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "ZXbKWwlOY1Dr"
      },
      "source": [
        "learn = load_learner(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "1ou-HOjcY1Dr"
      },
      "source": [
        "img = open_image(PATH/'test/a03-014.png');\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "ye9DOBMaY1Ds"
      },
      "source": [
        "res = learn.predict(img)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {},
        "heading_collapsed": true,
        "hidden": true,
        "id": "KcGDi9h4Y1Ds"
      },
      "source": [
        "print(str(res))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}